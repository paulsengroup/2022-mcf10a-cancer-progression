#!/usr/bin/env python3

# Copyright (C) 2023 Roberto Rossini <roberros@uio.no>
#
# SPDX-License-Identifier: MIT

import argparse
import collections
import functools
import itertools
import logging
import multiprocessing as mp
import pathlib
import typing
from typing import Dict, List, Tuple, Union

import bioframe as bf
import numpy as np
import numpy.typing as npt
import pandas as pd
import scipy.stats as ss


def make_cli():
    cli = argparse.ArgumentParser()

    cli.add_argument(
        "dchic-bedgraph",
        type=pathlib.Path,
        help="Path to the (sub)compartment bedGraph generated by dcHiC.",
    )
    cli.add_argument(
        "--domains",
        type=pathlib.Path,
        nargs="+",
        required=True,
        help="Comma-separated list of domain files in BED format generated by robomics/call_tad_cliques.\n"
        "Should be in the same order as conditions (i.e. cell types) found in the bedGraph generated by dcHiC.",
    )
    cli.add_argument(
        "--cliques",
        type=pathlib.Path,
        nargs="+",
        help="Comma-separated list of clique files in TSV format generated by robomics/call_tad_cliques.\n"
        "Should be in the same order as conditions (i.e. cell types) found in the bedGraph generated by dcHiC.",
    )

    cli.add_argument(
        "-o",
        "--output-folder",
        type=pathlib.Path,
        required=True,
        help="Path to folder where to store output files.",
    )

    cli.add_argument(
        "--force",
        action="store_true",
        default=False,
        help="Overwrite existing files (if any).",
    )

    cli.add_argument(
        "--use-subcompartment-scores",
        action="store_true",
        default=False,
        help="Use subcompartment scores instead of subcompartment labels to annotate TADs/cliques.",
    )

    cli.add_argument("--seed", type=int, default=3960467180, help="Seed to use for PRNG.")

    cli.add_argument(
        "--nproc",
        type=int,
        choices=range(1, mp.cpu_count() + 1),
        default=mp.cpu_count(),
        help="Maximum number of parallel processes.",
    )

    return cli


def handle_path_collisions(*paths: pathlib.Path) -> None:
    collisions = [p for p in paths if p.exists()]

    if len(collisions) != 0:
        collisions = "\n - ".join((str(p) for p in collisions))
        raise RuntimeError(
            "Refusing to overwrite file(s):\n" f" - {collisions}\n" "Pass --force to overwrite existing file(s)."
        )


@functools.cache
def get_subcompartment_ranks() -> dict:
    compartment_labels = tuple(["B3", "B2", "B1", "B0", "A0", "A1", "A2", "A3"])
    return {k: v for v, k in enumerate(compartment_labels)}


@functools.cache
def get_output_df_columns() -> List[str]:
    return [f"{s}.state" for s in get_subcompartment_ranks().keys()] + [
        "state.mode",
        "unimodality.score1",
        "unimodality.score2",
        "stderr",
        "mean_abs_dev",
    ]


def import_subcomps(path_to_bedgraph: pathlib.Path) -> Dict[str, pd.DataFrame]:
    df = pd.read_table(path_to_bedgraph)
    df1 = df[["chrom", "start", "end", "padj"]]

    states = df.filter(regex=r".*\.state")
    scores = df.filter(regex=r".*\.score")
    assert len(states.columns) == len(scores.columns)

    dfs = {}
    for state_col, score_col in zip(states, scores):
        label = score_col.removesuffix(".score")
        df2 = df1.copy()
        df2["state"] = states[state_col]
        df2["score"] = scores[score_col]
        dfs[label] = df2

    return dfs


def import_cliques(path_to_cliques: Union[pathlib.Path, None]) -> Union[pd.DataFrame, None]:
    if path_to_cliques is None:
        return None
    df = pd.read_table(path_to_cliques).rename(columns={"name": "clique"})
    assert df.columns.tolist() == ["clique", "tad_ids", "size"]
    df["tad_ids"] = df["tad_ids"].apply(lambda ids: [int(tid) for tid in ids.split(",")])
    return df.set_index("clique")


def import_domains(path_to_domains: pathlib.Path) -> pd.DataFrame:
    return pd.read_table(path_to_domains, names=bf.SCHEMAS["bed6"][0:4]).rename(columns={"name": "id"}).set_index("id")


def overlap_domains_with_subcomps(subcomps: pd.DataFrame, domains: pd.DataFrame) -> pd.DataFrame:
    return (
        bf.overlap(domains.drop_duplicates(), subcomps, suffixes=("", "_"))
        .drop(columns=["chrom_", "start_", "end_"])
        .rename(columns=lambda c: c.rstrip("_"))
        .convert_dtypes()
    )


def compute_state_distribution(df: pd.DataFrame) -> collections.Counter:
    return collections.Counter(df["state"].tolist())


def compute_modal_state(counts: collections.Counter) -> List[str]:
    mode = []
    mode_freq = 0
    for subcomp, count in counts.most_common():
        if count > mode_freq:
            mode = [subcomp]
            mode_freq = count
        elif count == mode_freq:
            mode.append(subcomp)
        else:
            break

    return mode


def compute_stderr(scores: npt.NDArray) -> float:
    return np.std(scores) / np.sqrt(len(scores))


def compute_mean_absolute_deviation(scores: npt.NDArray) -> float:
    return typing.cast(float, np.mean(np.abs(scores - np.mean(scores))))


def randomize_scores(scores: npt.NDArray) -> npt.NDArray:
    return scores + 0.5 + np.random.uniform(-0.5, 0.5, len(scores))


def test_state_for_unimodality(scores: npt.NDArray) -> Tuple[float, float]:
    assert ((0.0 <= scores) & (scores <= 8.0)).all()

    if len(scores) < 3:
        return np.nan, np.nan

    def sse(v1, v2):
        assert len(v1) == len(v2)
        return np.sum(((v1 / v1.max()) - (v2 / v2.max())) ** 2)

    x = np.linspace(0, 8, 100)

    # Fit distribution while fixing loc
    hist, _ = np.histogram(scores, bins=8, range=(0, 8))
    c, loc, scale = ss.genextreme.fit(scores, floc=np.argmax(hist))
    sse1 = sse(ss.gaussian_kde(scores)(x), ss.genextreme(c=c, loc=loc, scale=scale).pdf(x))

    c, loc, scale = ss.genextreme.fit(scores)
    sse2 = sse(ss.gaussian_kde(scores)(x), ss.genextreme(c=c, loc=loc, scale=scale).pdf(x))

    return sse1, sse2


def compute_state_stats(df: pd.DataFrame, use_subcompartment_scores: bool) -> Tuple:
    assert len(df) != 0
    counts = compute_state_distribution(df)

    mode = compute_modal_state(counts)

    if use_subcompartment_scores:
        scores = df["score"].to_numpy()
        unimodality_score, unimodality_pval = test_state_for_unimodality(scores)
    else:
        scores = df["state"].map(get_subcompartment_ranks()).to_numpy()
        unimodality_score, unimodality_pval = test_state_for_unimodality(randomize_scores(scores))

    counts = np.array([counts[subcmp] for subcmp in get_subcompartment_ranks().keys()])

    return (
        *counts,
        ",".join(mode),
        unimodality_score,
        unimodality_pval,
        compute_stderr(scores),
        compute_mean_absolute_deviation(scores),
    )


def compute_stats_for_tad(key, grp, use_subcompartment_scores):
    result = compute_state_stats(grp[["state", "score"]], use_subcompartment_scores)
    return list(key) + list(result)


def compute_state_stats_for_tads(df: pd.DataFrame, use_subcompartment_scores: bool, ppool) -> pd.DataFrame:
    task_gen = (tuple([key, grp, use_subcompartment_scores]) for key, grp in df.groupby(by=["chrom", "start", "end"]))
    data = ppool.starmap(compute_stats_for_tad, task_gen)
    return pd.DataFrame(data, columns=["chrom", "start", "end"] + get_output_df_columns())


def compute_state_stats_for_clique(clique, domains, tad_ids, use_subcompartment_scores: bool):
    cols = domains.filter(regex=r"\.state$").columns.tolist()
    states = pd.DataFrame(data=[domains.loc[tid, cols] for tid in tad_ids], columns=cols)
    states = pd.Series(
        itertools.chain.from_iterable(
            ([idx.removesuffix(".state")] * count for idx, count in states.sum(axis="index").items())
        ),
        name="state",
    )
    return [clique] + list(compute_state_stats(states.to_frame(), use_subcompartment_scores))


def annotate_cliques(cliques: pd.DataFrame, domains: pd.DataFrame, use_subcompartment_scores: bool, ppool):
    task_gen = (
        tuple([clique, domains, tad_ids, use_subcompartment_scores]) for clique, (tad_ids, _) in cliques.iterrows()
    )
    data = ppool.starmap(compute_state_stats_for_clique, task_gen)

    return pd.DataFrame(data=data, columns=["clique"] + get_output_df_columns())


def annotate_domains(
    subcomps: pd.DataFrame, domains: pd.DataFrame, use_subcompartment_scores: bool, ppool
) -> pd.DataFrame:
    df = overlap_domains_with_subcomps(subcomps, domains)
    return compute_state_stats_for_tads(df, use_subcompartment_scores, ppool)


def setup_logger(level=logging.INFO):
    logging.basicConfig(format="[%(asctime)s] %(levelname)s: %(message)s")
    logging.getLogger().setLevel(level)


def main():
    args = vars(make_cli().parse_args())

    domain_files = args["domains"]
    clique_files = args.get("cliques", [None] * len(domain_files))

    subcomp_dfs = import_subcomps(args["dchic-bedgraph"])
    labels = tuple(subcomp_dfs.keys())

    if len(domain_files) != len(labels):
        raise RuntimeError(f"Expected {len(labels)} domain file(s), found {len(domain_files)}")

    if len(clique_files) != len(labels):
        raise RuntimeError(f"Expected {len(labels)} clique file(s), found {len(clique_files)}")

    np.random.seed(args["seed"])

    outfolder = args["output_folder"]
    outfolder.mkdir(parents=True, exist_ok=True)
    with mp.Pool(args["nproc"]) as ppool:
        for label, dom_bed, clique_tsv in zip(labels, domain_files, clique_files):
            logging.info("[%s] annotating domains...", label)
            outfile = outfolder / dom_bed.name
            if not args["force"]:
                handle_path_collisions(outfile)

            doms = annotate_domains(
                subcomp_dfs[label], import_domains(dom_bed), args["use_subcompartment_scores"], ppool
            )
            logging.info("[%s] writing domains to %s...", label, outfile)
            doms.to_csv(outfile, sep="\t", index=False, header=True, na_rep="nan")

            if clique_tsv is None:
                logging.info("[%s] clique file not available. SKIPPING clique annotation!", label)
                continue

            logging.info("[%s] annotating cliques...", label)
            outfile = outfolder / clique_tsv.name
            if not args["force"]:
                handle_path_collisions(outfile)

            cliques = annotate_cliques(import_cliques(clique_tsv), doms, args["use_subcompartment_scores"], ppool)
            logging.info("[%s] writing cliques to %s...", label, outfile)
            cliques.to_csv(outfile, sep="\t", index=False, header=True, na_rep="nan")


if __name__ == "__main__":
    setup_logger()
    main()
